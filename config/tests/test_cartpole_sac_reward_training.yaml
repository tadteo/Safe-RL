# Configuaration for the goal hazard car environement

experiment_name : 'Test_Cartpole_SAC'

training: True
render : False
logging_level : "NO_LOG"

has_continuous_action_space : False

agent_kind : 'SAC'
reward_kind: 'REWARD'

environment: 'CartPole-v1'

#the start and the end of the section of the vector we are interested in
# goal_start: 0
# goal_end: 0

epochs : 1
steps_per_epoch : 1000

#ON POLICY parameters
on_policy : False

# OFF POLICY parameters
off_policy : True
update_frequency: 64 #execute a step of training after this number of environment steps
steps_in_future:  10
batch_size: 32

discount_factor: 0.99
initial_variance: 1000
final_variance: 0.0001


state_in_memory: 3

#agent hyperparameters
alpha : 0.2
gamma : 0.99
polyak : 0.995
learning_rate : 0.001
epsilon_start : 0.9
epsilon_end : 0.05
epsilon_decay : 0.995
