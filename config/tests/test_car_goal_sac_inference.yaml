# Configuaration for the goal hazard car environement

experiment_name : 'Test_CarGoalHazardSAC'

training: False
render : False
logging_level : "NO_LOG"

agent_kind : 'SAC'

environment:
  #The environment to use
  robot_base: 'xmls/car.xml'
  task : 'goal'
  observation_flatten : True
  observe_goal_lidar : True
  observe_hazards : False #True
  constrain_hazards : True
  # lidar_max_dist : 3
  lidar_num_bins : 16
  hazards_num : 4
  observe_sensors : False # Disable visualizations of internal sensors for simpler state management    
  continue_goal: True # If true, draw a new goal after achievement
  lidar_max_dist: 10  # Maximum distance for lidar sensitivity (if None, exponential distance)

has_continuous_action_space : True

#the start and the end of the section of the vector we are interested in
# goal_start: 0
# goal_end: 16

epochs : 1
steps_per_epoch : 1000

#agent hyperparameters
alpha : 0.2
gamma : 0.99
polyak : 0.995
learning_rate : 0.001

# OFF POLICY parameters
off_policy : True
update_frequency: 64 #execute a step of training after this number of environment steps
steps_in_future:  10
batch_size: 32

discount_factor: 0.99

state_in_memory: 3 #number of states observed used as single observation
