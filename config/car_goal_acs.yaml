# Configuaration for the goal hazard car environement

experiment_name : 'CarGoal_ACS'

training: True

agent_kind : 'ACS'

environment:
  #The environment to use
  robot_base: 'xmls/car.xml'
  task : 'goal'
  observation_flatten : True
  observe_goal_lidar : True
  observe_hazards : False #True
  constrain_hazards : True
  # lidar_max_dist : 3
  lidar_num_bins : 16
  hazards_num : 4
  observe_sensors : False # Disable visualizations of internal sensors for simpler state management    
  continue_goal: True  # If true, draw a new goal after achievement
  lidar_max_dist: 10  # Maximum distance for lidar sensitivity (if None, exponential distance)

has_continuous_action_space : True

#the start and the end of the section of the vector we are interested in
# goal_start: 0
# goal_end: 16

render : True
epochs : 100
steps_per_epoch : 10000

#ON POLICY parameters
on_policy : False

# OFF POLICY parameters
off_policy : True
update_frequency: 214 #execute a step of training after this number of environment steps
steps_in_future:  10
batch_size: 64

discount_factor: 0.99
initial_variance: 1000
final_variance: 0.0001


state_in_memory: 1 #number of states observed used as single observation

#Hyperparameters
learning_rate : 0.001
