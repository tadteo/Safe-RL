# Configuaration for the goal hazard car environement

experiment_name : 'Cartpole_ACS_distance'

training: True
render : False
has_continuous_action_space : False

agent_kind : 'ACS'
reward_kind: 'DISTANCE'
environment: 'CartPole-v1'

#the start and the end of the section of the vector we are interested in
goal_start: 0
goal_end: 0


epochs : 100
steps_per_epoch : 10000

#ON POLICY parameters
on_policy : False

# OFF POLICY parameters
off_policy : True
update_frequency: 128 #execute a step of training after this number of environment steps
steps_in_future:  10
batch_size: 64

discount_factor: 0.99
initial_variance: 1000
final_variance: 0.0001


state_in_memory: 5

#agent hyperparameters
learning_rate : 0.001
epsilon_start : 0.9
epsilon_end : 0.05
epsilon_decay : 0.995
